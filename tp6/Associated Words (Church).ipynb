{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/march/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/march/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freq_one(word, tokens):\n",
    "    'Frecuencia de una palabra en un texto (Church 1990)'\n",
    "    return sum((1 for t in tokens if t == word)) / float(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freq_two(first, second, tokens, win_size=5):\n",
    "    '''\n",
    "    Frecuencia de dos palabras en un texto (Church 1990)\n",
    "    \n",
    "    Aplica correccion de (w - 1) para compensar por múltiples conteos.\n",
    "    \n",
    "    O(|tokens| * win_size)\n",
    "    '''\n",
    "    count = 0\n",
    "    for idx in range(len(tokens)):\n",
    "        left = max(0, idx - win_size + 1)\n",
    "        if tokens[idx] == second:\n",
    "            for x in tokens[left:idx]:\n",
    "                if x == first:\n",
    "                    count += 1\n",
    "    return count / (win_size - 1) / float(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freq_two_fast(first_token_pos, second_token_pos, token_count, win_size=5):\n",
    "    '''\n",
    "    Equivalente a freq_two pero más veloz.\n",
    "    \n",
    "    Args:\n",
    "        first_token_pos :: [int] lista de posiciones en el texto donde se encuentra el token a izq\n",
    "        second_token_pos :: [int] lista de posiciones en el texto donde se encuentra el token a der\n",
    "        token_count :: int cantidad te tokens en el texto\n",
    "        \n",
    "    O(#apariciones token 1 + #apariciones token 2)\n",
    "    '''\n",
    "    s_it = reversed(second_token_pos)\n",
    "    f_it = reversed(first_token_pos)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    try:\n",
    "        f_idx = next(f_it)\n",
    "        s_idx = next(s_it)\n",
    "        while True:\n",
    "            while (f_idx > s_idx):\n",
    "                f_idx = next(f_it)\n",
    "            local_f_it, f_it = itertools.tee(f_it)\n",
    "            local_f_idx = f_idx\n",
    "            while (s_idx - local_f_idx < win_size):\n",
    "                if (s_idx - local_f_idx > 0):\n",
    "                    count += 1\n",
    "                local_f_idx = next(local_f_it)\n",
    "            s_idx = next(s_it)\n",
    "    except StopIteration:\n",
    "        return count / (win_size - 1) / token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def info(first, second, tokens, win_size=5):\n",
    "    'Mutual information of two tokens (Church 1990)'\n",
    "    f2 = freq_two(first, second, tokens, win_size)\n",
    "    if f2 < 6:\n",
    "        return None\n",
    "    fa = freq_one(first, tokens)\n",
    "    fb = freq_one(second, tokens)\n",
    "    q = f2 / (fa * fb)\n",
    "    return np.log2(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def q_fast(first_token_pos, second_token_pos, token_count, win_size=5):\n",
    "    f2 = freq_two_fast(first_token_pos, second_token_pos, token_count, win_size)\n",
    "    #if f2 < (6 / (win_size - 1) / token_count):\n",
    "    #    return None\n",
    "    if f2 < 1:\n",
    "        return None\n",
    "    fa = len(first_token_pos)\n",
    "    fb = len(second_token_pos)\n",
    "    q = f2 / (fa * fb)\n",
    "    return q "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punc_translator = str.maketrans(dict(zip(string.punctuation, [None] * len(string.punctuation))))\n",
    "def tokenize(string):\n",
    "    'Returns list of tokens'\n",
    "    # TODO: Cambiar split por: https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer\n",
    "    words = string.split(' ')  # [Palabra]\n",
    "    retoken = [ t.lower()\n",
    "        for w in words\n",
    "        for t in nltk.word_tokenize(w)\n",
    "    ] \n",
    "    no_punt = [ t\n",
    "        for t in retoken\n",
    "        if t.translate(punc_translator) != ''\n",
    "    ]\n",
    "    return no_punt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docno = []\n",
    "corpus = []\n",
    "toggle = 0\n",
    "with open('ap/ap.txt','r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('<DOCNO>'):\n",
    "            line_new = line.replace('<DOCNO> ','')\n",
    "            line_new = line_new.replace(' </DOCNO>\\n','')\n",
    "            docno.append(line_new)\n",
    "        if toggle:\n",
    "            corpus.append(line)\n",
    "            toggle = 0\n",
    "        if line.startswith('<TEXT>'):\n",
    "            toggle = 1        \n",
    "docs = dict(zip(docno, corpus))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = next(iter(docs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_tokens = tokenize(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_commons = [x[0] for x in Counter(sorted(a_tokens)).most_common(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_commons_pos = {\n",
    "    token : [idx for idx, t in enumerate(a_tokens) if t == token]\n",
    "    for token in a_commons\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the the 8.0 8.0 True\n",
      "the a 3.0 3.0 True\n",
      "the and 3.0 3.0 True\n",
      "the said 4.0 4.0 True\n",
      "the was 5.000000000000001 5.000000000000001 True\n",
      "the of 7.0 7.0 True\n",
      "the 's 7.0 7.0 True\n",
      "the boy 9.0 9.0 True\n",
      "the he 0.0 0.0 True\n",
      "the school 6.0 6.0 True\n"
     ]
    }
   ],
   "source": [
    "first = a_commons[0]\n",
    "for j in range(10):\n",
    "    second = a_commons[j]\n",
    "    f = freq_two(first, second, a_tokens)\n",
    "    f2 = freq_two_fast(a_commons_pos[first], a_commons_pos[second], len(a_tokens))\n",
    "    print(first, second, f2 * len(a_tokens) * 4, f * len(a_tokens) * 4, f == f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Top 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PICKLE_DIR = 'pickles'\n",
    "EJ1_TOKENS_PATH = os.path.join(PICKLE_DIR, 'ej1_tokens.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(PICKLE_DIR):\n",
    "    os.mkdir(PICKLE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(EJ1_TOKENS_PATH):\n",
    "    token_docs = {\n",
    "        docno : tokenize(text)\n",
    "        for docno, text in docs.items()\n",
    "    }\n",
    "    with open(EJ1_TOKENS_PATH, 'wb') as f:\n",
    "        pickle.dump(token_docs, f)\n",
    "else:\n",
    "    with open(EJ1_TOKENS_PATH, 'rb') as f:\n",
    "        token_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tokens = [t for tokens in token_docs.values() for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_tokens_counts = Counter(sorted(all_tokens)).most_common(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_tokens = [x[0] for x in top_tokens_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_docs = {\n",
    "    docno : tokens\n",
    "    for docno, tokens in token_docs.items()\n",
    "    if len(tokens) > 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_tokens_set = set(top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Armamos la matriz de co-frecuencias\n",
    "win_size = 5\n",
    "co_freq = defaultdict(lambda : defaultdict(int))\n",
    "freq = defaultdict(int)\n",
    "\n",
    "for tokens in token_docs.values():\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] in top_tokens_set:\n",
    "            freq[tokens[i]] += 1\n",
    "            for k in range(1, min(len(tokens) - i, win_size - 1)):\n",
    "                if tokens[i + k] in top_tokens_set:\n",
    "                    dists.append(i - i + k)\n",
    "                    co_freq[tokens[i]][tokens[i+k]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ajustamos el valor por (win_size - 1)\n",
    "for t1 in co_freq:\n",
    "    for t2 in co_freq[t1]:\n",
    "        co_freq[t1][t2] /= (win_size - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculamos N\n",
    "N = sum([len(tokens) for tokens in token_docs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relations = {\n",
    "    (t1, t2) : np.log2((co_freq[t1][t2] / N) / (freq[t1] * freq[t2] / (N * N)))\n",
    "    for t1 in co_freq\n",
    "    for t2 in co_freq[t1]\n",
    "    if co_freq[t1][t2] * (win_size - 1) > 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_relations = sorted([r for r in relations.items() if r[0] != 0.0], \n",
    "                       key=lambda kv: kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('prime', 'minister'), 8.6837530270268442),\n",
       " (('human', 'rights'), 8.5526180603043116),\n",
       " (('interest', 'rates'), 8.3645610699064417),\n",
       " (('south', 'africa'), 8.169449800993279),\n",
       " (('eastern', 'europe'), 7.9623518920134355),\n",
       " (('stock', 'exchange'), 7.6810756686074395),\n",
       " (('west', 'german'), 7.6212728580275799),\n",
       " (('district', 'judge'), 7.5351932278390263),\n",
       " (('news', 'conference'), 7.528537573654515),\n",
       " (('united', 'states'), 7.442257478147325),\n",
       " (('west', 'germany'), 7.3638379235443185),\n",
       " (('air', 'force'), 7.3537929912865181),\n",
       " (('told', 'reporters'), 7.3484801332298364),\n",
       " (('communist', 'party'), 7.3327744825370926),\n",
       " (('white', 'house'), 7.3271189120223053)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_relations[:15]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
