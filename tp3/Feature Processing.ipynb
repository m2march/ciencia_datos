{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Processing\n",
    "\n",
    "En este notebook obtenemos los features de interés a partir de las matrices de mediciones de los sujetos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "import glob\n",
    "import os.path\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "import scipy.signal as scs\n",
    "import pandas as pd\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiciones globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_dir = 'pickles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(pickle_dir):\n",
    "    os.mkdir(pickle_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = 'dataset'\n",
    "fs = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificación de sujetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUBJECT_FILES = 'subjects_files.pkl'\n",
    "subjects_files_path = os.path.join(pickle_dir, SUBJECT_FILES)\n",
    "\n",
    "if not os.path.isfile(subjects_files_path):\n",
    "    subjects = glob.glob('dataset/*.mat')\n",
    "    matrix_files = sorted(subjects)  # dataset/P01.mat ...\n",
    "    matrix_names = [os.path.basename(n).replace('.mat', '') for n in matrix_files]  # P01.mat ...\n",
    "    \n",
    "    with open(os.path.join(pickle_dir, SUBJECT_FILES), 'wb') as f:\n",
    "        pickle.dump(matrix_files, f, protocol=2)\n",
    "else:\n",
    "    with open(os.path.join(pickle_dir, SUBJECT_FILES), 'rb') as f:\n",
    "        matrix_files = pickle.load(f)  # dataset/P01.mat ...\n",
    "        matrix_names = [os.path.basename(n).replace('.mat', '') for n in matrix_files]  # P01.mat ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potencia en bandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nombres de archivos\n",
    "\n",
    "BAND_POWER_MEAN = 'band_power_mean.pkl'\n",
    "BAND_POWER_STD = 'band_power_std.pkl'\n",
    "BAND_POWER_NORM_MEAN = 'band_power_norm_mean.pkl'\n",
    "BAND_POWER_NORM_STD = 'band_power_norm_std.pkl'\n",
    "band_power_mean_file = os.path.join(pickle_dir, BAND_POWER_MEAN)\n",
    "band_power_std_file = os.path.join(pickle_dir, BAND_POWER_STD)\n",
    "band_power_norm_mean_file = os.path.join(pickle_dir, BAND_POWER_NORM_MEAN)\n",
    "band_power_norm_std_file = os.path.join(pickle_dir, BAND_POWER_NORM_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inicialización variables\n",
    "band_names = ['alpha', 'beta', 'gamma', 'delta', 'theta']\n",
    "\n",
    "band_mean = pd.DataFrame(index=matrix_names, columns=band_names)\n",
    "band_norm_mean= pd.DataFrame(index=matrix_names, columns=band_names)\n",
    "band_std = pd.DataFrame(index=matrix_names, columns=band_names)\n",
    "band_norm_std= pd.DataFrame(index=matrix_names, columns=band_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/P01.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\signal\\spectral.py:1637: UserWarning: nperseg = 256 is greater than input length  = 201, using nperseg = 201\n",
      "  .format(nperseg, input_length))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/P02.mat\n",
      "dataset/P03.mat\n",
      "dataset/P04.mat\n",
      "dataset/P05.mat\n",
      "dataset/P06.mat\n",
      "dataset/P07.mat\n",
      "dataset/P08.mat\n",
      "dataset/P09.mat\n",
      "dataset/P10.mat\n",
      "dataset/S01.mat\n",
      "dataset/S02.mat\n",
      "dataset/S03.mat\n",
      "dataset/S04.mat\n",
      "dataset/S05.mat\n",
      "dataset/S06.mat\n",
      "dataset/S07.mat\n",
      "dataset/S08.mat\n",
      "dataset/S09.mat\n",
      "dataset/S10.mat\n"
     ]
    }
   ],
   "source": [
    "# Calculo de información\n",
    "\n",
    "for idx in range(len(matrix_names)):\n",
    "    file = matrix_files[idx]\n",
    "    print(file)\n",
    "    subject_name = matrix_names[idx]\n",
    "    data = sio.loadmat(file)\n",
    "    data_array = data['data']\n",
    "\n",
    "    # potencia: epoch x electrodo x freq\n",
    "    freq, Pxx_trials_subjects = scs.welch(data_array[:,:,:], fs=fs)\n",
    "\n",
    "    # potencia: epoch x freq \n",
    "    Pxx_epoch_subjects = np.mean(Pxx_trials_subjects, axis=1)\n",
    "\n",
    "    # potencia (de banda): epoch\n",
    "    Pxx_epoch_delta_subjects = np.sum(Pxx_epoch_subjects[:, freq < 4], axis=1)\n",
    "    Pxx_epoch_theta_subjects = np.sum(Pxx_epoch_subjects[:, (freq >= 4)*(freq < 8)], axis=1)\n",
    "    Pxx_epoch_beta_subjects = np.sum(Pxx_epoch_subjects[:, (freq >= 13)*(freq < 30)], axis=1)\n",
    "    Pxx_epoch_gamma_subjects = np.sum(Pxx_epoch_subjects[:, freq >= 30], axis=1)\n",
    "    Pxx_epoch_alpha_subjects = np.sum(Pxx_epoch_subjects[:, freq >= 30], axis=1)\n",
    "    \n",
    "    band_mean['delta'][subject_name] = Pxx_epoch_delta_subjects.mean()\n",
    "    band_mean['theta'][subject_name] = Pxx_epoch_theta_subjects.mean()\n",
    "    band_mean['beta'][subject_name] = Pxx_epoch_beta_subjects.mean()\n",
    "    band_mean['gamma'][subject_name] = Pxx_epoch_gamma_subjects.mean()\n",
    "    band_mean['alpha'][subject_name] = Pxx_epoch_alpha_subjects.mean()\n",
    "    \n",
    "    band_std['delta'][subject_name] = Pxx_epoch_delta_subjects.std()\n",
    "    band_std['theta'][subject_name] = Pxx_epoch_theta_subjects.std()\n",
    "    band_std['beta'][subject_name] = Pxx_epoch_beta_subjects.std()\n",
    "    band_std['gamma'][subject_name] = Pxx_epoch_gamma_subjects.std()\n",
    "    band_std['alpha'][subject_name] = Pxx_epoch_alpha_subjects.std()\n",
    "    \n",
    "    band_sum = np.array([\n",
    "        Pxx_epoch_delta_subjects,\n",
    "        Pxx_epoch_theta_subjects,\n",
    "        Pxx_epoch_beta_subjects,\n",
    "        Pxx_epoch_gamma_subjects,\n",
    "        Pxx_epoch_alpha_subjects\n",
    "    ]).sum(axis=0)\n",
    "    \n",
    "    band_norm_mean['delta'][subject_name] = (Pxx_epoch_delta_subjects / band_sum).mean()\n",
    "    band_norm_mean['theta'][subject_name] = (Pxx_epoch_theta_subjects / band_sum).mean()\n",
    "    band_norm_mean['beta'][subject_name] = (Pxx_epoch_beta_subjects / band_sum).mean()\n",
    "    band_norm_mean['gamma'][subject_name] = (Pxx_epoch_gamma_subjects / band_sum).mean()\n",
    "    band_norm_mean['alpha'][subject_name] = (Pxx_epoch_alpha_subjects / band_sum).mean()\n",
    "    \n",
    "    band_norm_std['delta'][subject_name] = (Pxx_epoch_delta_subjects / band_sum).std()\n",
    "    band_norm_std['theta'][subject_name] = (Pxx_epoch_theta_subjects / band_sum).std()\n",
    "    band_norm_std['beta'][subject_name] = (Pxx_epoch_beta_subjects / band_sum).std()\n",
    "    band_norm_std['gamma'][subject_name] = (Pxx_epoch_gamma_subjects / band_sum).std()\n",
    "    band_norm_std['alpha'][subject_name] = (Pxx_epoch_alpha_subjects / band_sum).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grabación\n",
    "with open(band_power_mean_file, 'wb') as f:\n",
    "    pickle.dump(band_mean, f, protocol=2)\n",
    "\n",
    "with open(band_power_std_file, 'wb') as f:\n",
    "    pickle.dump(band_std, f, protocol=2)\n",
    "\n",
    "with open(band_power_norm_mean_file, 'wb') as f:\n",
    "    pickle.dump(band_norm_mean, f, protocol=2)\n",
    "\n",
    "with open(band_power_norm_std_file, 'wb') as f:\n",
    "    pickle.dump(band_norm_std, f, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información intra-electrodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subject_entropy_var(subject_matrix):\n",
    "    \"Matriz entropía epoch x electrodo\"\n",
    "    H = np.zeros((subject_matrix.shape[0], subject_matrix.shape[1]))\n",
    "    for i in range(subject_matrix.shape[0]):\n",
    "        for j in range(subject_matrix.shape[1]):\n",
    "            hist, bin_edges = np.histogram(subject_matrix[i, j, :], bins='scott')\n",
    "            H [i, j] = sp.stats.entropy(hist/sum(hist))\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INTRA_ENTROPY = 'intra_entropy.pkl'\n",
    "intra_entropy_file = os.path.join(pickle_dir, INTRA_ENTROPY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intra_entropy_columns = ['mean', 'std']\n",
    "intra_entropy = pd.DataFrame(index=matrix_names, columns=intra_entropy_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/P01.mat\n",
      "dataset/P02.mat\n",
      "dataset/P03.mat\n",
      "dataset/P04.mat\n",
      "dataset/P05.mat\n",
      "dataset/P06.mat\n",
      "dataset/P07.mat\n",
      "dataset/P08.mat\n",
      "dataset/P09.mat\n",
      "dataset/P10.mat\n",
      "dataset/S01.mat\n",
      "dataset/S02.mat\n",
      "dataset/S03.mat\n",
      "dataset/S04.mat\n",
      "dataset/S05.mat\n",
      "dataset/S06.mat\n",
      "dataset/S07.mat\n",
      "dataset/S08.mat\n",
      "dataset/S09.mat\n",
      "dataset/S10.mat\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(matrix_names)):\n",
    "    file = matrix_files[idx]\n",
    "    print(file)\n",
    "    subject_name = matrix_names[idx]\n",
    "    data = sio.loadmat(file)\n",
    "    data_array = data['data']\n",
    "    \n",
    "    H = subject_entropy_var(data_array)  # epoch x electrodo\n",
    "    H_epoch = H.mean(axis=1)  # epoch\n",
    "   \n",
    "    intra_entropy['mean'][subject_name] = H_epoch.mean()\n",
    "    intra_entropy['std'][subject_name] = H_epoch.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(intra_entropy_file, 'wb') as f:\n",
    "    pickle.dump(intra_entropy, f, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información inter-electrodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a el tiempo que toma calcular la información mutua entre electrodos, este feature se extrae mediante un script. El script está pensado para que ejecute en una pc remota. Como consecuencia escribe en un log su progreso.\n",
    "\n",
    "A continuación vemos el resultado obtenido por el [script](https://github.com/m2march/ciencia_datos/blob/master/tp3/tp3_IH.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tp3_IH import INTER_ENTROPY\n",
    "\n",
    "inter_electrodo = pd.read_pickle(os.path.join(pickle_dir, INTER_ENTROPY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P01</th>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.001689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P02</th>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P03</th>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P04</th>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P05</th>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.000391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P06</th>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P07</th>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P08</th>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P09</th>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P10</th>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S01</th>\n",
       "      <td>0.034460</td>\n",
       "      <td>0.005470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S02</th>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S03</th>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.001754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S04</th>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.001243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S05</th>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S06</th>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S07</th>\n",
       "      <td>0.020333</td>\n",
       "      <td>0.014211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S08</th>\n",
       "      <td>0.004979</td>\n",
       "      <td>0.000499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S09</th>\n",
       "      <td>0.183400</td>\n",
       "      <td>0.020387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S10</th>\n",
       "      <td>0.022962</td>\n",
       "      <td>0.005535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean       std\n",
       "P01  0.002989  0.001689\n",
       "P02  0.003947  0.000634\n",
       "P03  0.000825  0.000142\n",
       "P04  0.000962  0.000267\n",
       "P05  0.001089  0.000391\n",
       "P06  0.000751  0.000080\n",
       "P07  0.001047  0.000172\n",
       "P08  0.002055  0.000370\n",
       "P09  0.001761  0.000229\n",
       "P10  0.001190  0.000465\n",
       "S01  0.034460  0.005470\n",
       "S02  0.002343  0.000392\n",
       "S03  0.004078  0.001754\n",
       "S04  0.006132  0.001243\n",
       "S05  0.001801  0.000358\n",
       "S06  0.001398  0.000019\n",
       "S07  0.020333  0.014211\n",
       "S08  0.004979  0.000499\n",
       "S09  0.183400  0.020387\n",
       "S10  0.022962  0.005535"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_electrodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
