{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Processing\n",
    "\n",
    "En este notebook obtenemos los features de interés a partir de las matrices de mediciones de los sujetos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "import glob\n",
    "import os.path\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "import scipy.signal as scs\n",
    "import pandas as pd\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiciones globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_dir = 'pickles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(pickle_dir):\n",
    "    os.mkdir(pickle_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = 'dataset'\n",
    "fs = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificación de sujetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT_FILES = 'subjects_files.pkl'\n",
    "subjects_files_path = os.path.join(pickle_dir, SUBJECT_FILES)\n",
    "\n",
    "if not os.path.isfile(subjects_files_path):\n",
    "    subjects = glob.glob('dataset/*.mat')\n",
    "    matrix_files = sorted(subjects)  # dataset/P01.mat ...\n",
    "    matrix_names = [os.path.basename(n).replace('.mat', '') for n in matrix_files]  # P01.mat ...\n",
    "    \n",
    "    with open(os.path.join(pickle_dir, SUBJECT_FILES), 'wb') as f:\n",
    "        pickle.dump(matrix_files, f, protocol=2)\n",
    "else:\n",
    "    with open(os.path.join(pickle_dir, SUBJECT_FILES), 'rb') as f:\n",
    "        matrix_files = pickle.load(f)  # dataset/P01.mat ...\n",
    "        matrix_names = [os.path.basename(n).replace('.mat', '') for n in matrix_files]  # P01.mat ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potencia en bandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nombres de archivos\n",
    "\n",
    "BAND_POWER_MEAN = 'band_power_mean.pkl'\n",
    "BAND_POWER_STD = 'band_power_std.pkl'\n",
    "BAND_POWER_NORM_MEAN = 'band_power_norm_mean.pkl'\n",
    "BAND_POWER_NORM_STD = 'band_power_norm_std.pkl'\n",
    "band_power_mean_file = os.path.join(pickle_dir, BAND_POWER_MEAN)\n",
    "band_power_std_file = os.path.join(pickle_dir, BAND_POWER_STD)\n",
    "band_power_norm_mean_file = os.path.join(pickle_dir, BAND_POWER_NORM_MEAN)\n",
    "band_power_norm_std_file = os.path.join(pickle_dir, BAND_POWER_NORM_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización variables\n",
    "band_names = ['alpha', 'beta', 'gamma', 'delta', 'theta']\n",
    "\n",
    "band_means = pd.DataFrame(index=matrix_names, columns=band_names)\n",
    "band_norm_means= pd.DataFrame(index=matrix_names, columns=band_names)\n",
    "band_std = pd.DataFrame(index=matrix_names, columns=band_names)\n",
    "band_norm_std= pd.DataFrame(index=matrix_names, columns=band_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculo de información\n",
    "\n",
    "for idx in range(len(matrix_names)):\n",
    "    file = matrix_files[idx]\n",
    "    print(file)\n",
    "    subject_name = matrix_names[idx]\n",
    "    data = sio.loadmat(file)\n",
    "    data_array = data['data']\n",
    "\n",
    "    # potencia: epoch x electrodo x freq\n",
    "    freq, Pxx_trials_subjects = scs.welch(data_array[:,:,:], fs=fs)\n",
    "\n",
    "    # potencia: epoch x freq \n",
    "    Pxx_epoch_subjects = np.mean(Pxx_trials_subjects, axis=1)\n",
    "\n",
    "    # potencia (de banda): epoch\n",
    "    Pxx_epoch_delta_subjects = np.sum(Pxx_epoch_subjects[:, freq < 4], axis=1)\n",
    "    Pxx_epoch_theta_subjects = np.sum(Pxx_epoch_subjects[:, (freq >= 4)*(freq < 8)], axis=1)\n",
    "    Pxx_epoch_beta_subjects = np.sum(Pxx_epoch_subjects[:, (freq >= 13)*(freq < 30)], axis=1)\n",
    "    Pxx_epoch_gamma_subjects = np.sum(Pxx_epoch_subjects[:, freq >= 30], axis=1)\n",
    "    Pxx_epoch_alpha_subjects = np.sum(Pxx_epoch_subjects[:, freq >= 30], axis=1)\n",
    "    \n",
    "    band_means['delta'][subject_name] = Pxx_epoch_delta_subjects.mean()\n",
    "    band_means['theta'][subject_name] = Pxx_epoch_theta_subjects.mean()\n",
    "    band_means['beta'][subject_name] = Pxx_epoch_beta_subjects.mean()\n",
    "    band_means['gamma'][subject_name] = Pxx_epoch_gamma_subjects.mean()\n",
    "    band_means['alpha'][subject_name] = Pxx_epoch_alpha_subjects.mean()\n",
    "    \n",
    "    band_std['delta'][subject_name] = Pxx_epoch_delta_subjects.std()\n",
    "    band_std['theta'][subject_name] = Pxx_epoch_theta_subjects.std()\n",
    "    band_std['beta'][subject_name] = Pxx_epoch_beta_subjects.std()\n",
    "    band_std['gamma'][subject_name] = Pxx_epoch_gamma_subjects.std()\n",
    "    band_std['alpha'][subject_name] = Pxx_epoch_alpha_subjects.std()\n",
    "    \n",
    "    band_sum = np.array([\n",
    "        Pxx_epoch_delta_subjects,\n",
    "        Pxx_epoch_theta_subjects,\n",
    "        Pxx_epoch_beta_subjects,\n",
    "        Pxx_epoch_gamma_subjects,\n",
    "        Pxx_epoch_alpha_subjects\n",
    "    ]).sum(axis=0)\n",
    "    \n",
    "    band_means['delta'][subject_name] = (Pxx_epoch_delta_subjects / band_sum).mean()\n",
    "    band_means['theta'][subject_name] = (Pxx_epoch_theta_subjects / band_sum).mean()\n",
    "    band_means['beta'][subject_name] = (Pxx_epoch_beta_subjects / band_sum).mean()\n",
    "    band_means['gamma'][subject_name] = (Pxx_epoch_gamma_subjects / band_sum).mean()\n",
    "    band_means['alpha'][subject_name] = (Pxx_epoch_alpha_subjects / band_sum).mean()\n",
    "    \n",
    "    band_std['delta'][subject_name] = (Pxx_epoch_delta_subjects / band_sum).std()\n",
    "    band_std['theta'][subject_name] = (Pxx_epoch_theta_subjects / band_sum).std()\n",
    "    band_std['beta'][subject_name] = (Pxx_epoch_beta_subjects / band_sum).std()\n",
    "    band_std['gamma'][subject_name] = (Pxx_epoch_gamma_subjects / band_sum).std()\n",
    "    band_std['alpha'][subject_name] = (Pxx_epoch_alpha_subjects / band_sum).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabación\n",
    "with open(band_power_mean_file, 'wb') as f:\n",
    "    pickle.dump(band_means, f, protocol=2)\n",
    "\n",
    "with open(band_power_std_file, 'wb') as f:\n",
    "    pickle.dump(band_std, f, protocol=2)\n",
    "\n",
    "with open(band_power_norm_mean_file, 'wb') as f:\n",
    "    pickle.dump(band_means, f, protocol=2)\n",
    "\n",
    "with open(band_power_norm_std_file, 'wb') as f:\n",
    "    pickle.dump(band_std, f, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información intra-electrodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subject_entropy_var(subject_matrix):\n",
    "    \"Matriz entropía epoch x electrodo\"\n",
    "    H = np.zeros((subject_matrix.shape[0], subject_matrix.shape[1]))\n",
    "    for i in range(subject_matrix.shape[0]):\n",
    "        for j in range(subject_matrix.shape[1]):\n",
    "            hist, bin_edges = np.histogram(subject_matrix[i, j, :], bins='scott')\n",
    "            H [i, j] = sp.stats.entropy(hist/sum(hist))\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INTRA_ENTROPY = 'intra_entropy.pkl'\n",
    "intra_entropy_file = os.path.join(pickle_dir, INTRA_ENTROPY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intra_entropy_columns = ['mean', 'std']\n",
    "intra_entropy = pd.DataFrame(index=matrix_names, columns=intra_entropy_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/P01.mat\n",
      "dataset/P02.mat\n",
      "dataset/P03.mat\n",
      "dataset/P04.mat\n",
      "dataset/P05.mat\n",
      "dataset/P06.mat\n",
      "dataset/P07.mat\n",
      "dataset/P08.mat\n",
      "dataset/P09.mat\n",
      "dataset/P10.mat\n",
      "dataset/S01.mat\n",
      "dataset/S02.mat\n",
      "dataset/S03.mat\n",
      "dataset/S04.mat\n",
      "dataset/S05.mat\n",
      "dataset/S06.mat\n",
      "dataset/S07.mat\n",
      "dataset/S08.mat\n",
      "dataset/S09.mat\n",
      "dataset/S10.mat\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(matrix_names)):\n",
    "    file = matrix_files[idx]\n",
    "    print(file)\n",
    "    subject_name = matrix_names[idx]\n",
    "    data = sio.loadmat(file)\n",
    "    data_array = data['data']\n",
    "    \n",
    "    H = subject_entropy_var(data_array)  # epoch x electrodo\n",
    "    H_epoch = H.mean(axis=1)  # epoch\n",
    "   \n",
    "    intra_entropy['mean'][subject_name] = H_epoch.mean()\n",
    "    intra_entropy['std'][subject_name] = H_epoch.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(intra_entropy_file, 'wb') as f:\n",
    "    pickle.dump(intra_entropy, f, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información inter-electrodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
